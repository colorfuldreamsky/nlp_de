{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context management\n",
    "\n",
    "In this notebook we go through some features of Rasa. It is commonly used for retrieval-based chatbots. We cover in this part the following topics:\n",
    "\n",
    "- intent and entities understanding,\n",
    "- the learning process of intent understanding,\n",
    "- state machine as a crucial part of chatbot conversation,\n",
    "- context management with Rasa core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent understanding\n",
    "\n",
    "In this section we use Rasa to build a very simple HR assistant bot. We can use Rasa as a server or use it directly from Python level. To start Rasa server you need to execute the following command:\n",
    "```python3 -m rasa_nlu.server --path projects &```\n",
    "It starts a server on default port 5000. You can test it using the request package. We should get the intent of the phrase `hi`.\n",
    "\n",
    "![](images/message_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': {'name': 'greet', 'confidence': 1.0}, 'entities': [], 'text': 'hi', 'project': 'default', 'model': 'fallback'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'greet'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_intent(sentence):\n",
    "    url = \"http://localhost:5000/parse\"\n",
    "    payload = {\"q\":sentence}\n",
    "    response = requests.get(url,params=payload)    \n",
    "    print(response.json())\n",
    "    intent = response.json()['intent']\n",
    "    if intent['confidence'] > 0.5: \n",
    "        return intent['name']\n",
    "    return response.json()\n",
    "\n",
    "get_intent(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': {'name': 'greet', 'confidence': 1.0}, 'entities': [], 'text': 'hello', 'project': 'default', 'model': 'fallback'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'greet'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_intent(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Rasa from Python level you need to prepare a config file that contains the pipeline and the filename of examples used for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = \"\"\"\n",
    "{\n",
    "  \"pipeline\": \"spacy_sklearn\",\n",
    "  \"path\" : \".\",\n",
    "  \"data\" : \".anna.json\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "config_file = open(\"config.json\", \"w\")\n",
    "config_file.write(co)\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data file contains examples that are used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "anna_common_examples = \"\"\"\n",
    "{\n",
    "  \"rasa_nlu_data\": {\n",
    "    \"entity_synonyms\": [\n",
    "      {\n",
    "        \"value\": \"candidate\",\n",
    "        \"synonyms\": [\"developer\", \"data scientist\"]\n",
    "      }\n",
    "    ],\n",
    "    \"common_examples\": [\n",
    "      {\n",
    "        \"text\": \"hey\", \n",
    "        \"intent\": \"greet\", \n",
    "        \"entities\": []\n",
    "      }, \n",
    "      {\n",
    "        \"text\": \"howdy\", \n",
    "        \"intent\": \"greet\", \n",
    "        \"entities\": []\n",
    "      }, \n",
    "      {\n",
    "        \"text\": \"hey there\",\n",
    "        \"intent\": \"greet\", \n",
    "        \"entities\": []\n",
    "      }, \n",
    "      {\n",
    "        \"text\": \"hello\", \n",
    "        \"intent\": \"greet\", \n",
    "        \"entities\": []\n",
    "      }, \n",
    "      {\n",
    "        \"text\": \"hi\", \n",
    "        \"intent\": \"greet\", \n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"good morning\",\n",
    "        \"intent\": \"greet\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"good evening\",\n",
    "        \"intent\": \"greet\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"dear sir\",\n",
    "        \"intent\": \"greet\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"yes\", \n",
    "        \"intent\": \"affirm\", \n",
    "        \"entities\": []\n",
    "      }, \n",
    "      {\n",
    "        \"text\": \"yep\", \n",
    "        \"intent\": \"affirm\", \n",
    "        \"entities\": []\n",
    "      }, \n",
    "      {\n",
    "        \"text\": \"yeah\", \n",
    "        \"intent\": \"affirm\", \n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"indeed\",\n",
    "        \"intent\": \"affirm\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"that's right\",\n",
    "        \"intent\": \"affirm\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"ok\",\n",
    "        \"intent\": \"affirm\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"great\",\n",
    "        \"intent\": \"affirm\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"right, thank you\",\n",
    "        \"intent\": \"affirm\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"add candidate\",\n",
    "        \"intent\": \"candidate_add\",\n",
    "        \"entities\": [\n",
    "            {\n",
    "      \"start\": 5,\n",
    "      \"end\": 13,\n",
    "      \"value\": \"candidate\",\n",
    "      \"entity\": \"candidate\"\n",
    "        }\n",
    "        ]\n",
    "      },         \n",
    "      {\n",
    "        \"text\": \"adding candidate\",\n",
    "        \"intent\": \"candidate_add\",\n",
    "        \"entities\": [\n",
    "            {\n",
    "              \"start\": 8,\n",
    "              \"end\": 16,\n",
    "              \"value\": \"candidate\",\n",
    "              \"entity\": \"candidate\"\n",
    "            }        \n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"please add candidate\",\n",
    "        \"intent\": \"candidate_add\",\n",
    "        \"entities\": []\n",
    "      },              \n",
    "      {\n",
    "        \"text\": \"please add new candidate\",\n",
    "        \"intent\": \"candidate_add\",\n",
    "        \"entities\": []\n",
    "      },           \n",
    "      {\n",
    "        \"text\": \"we have new prescreening upcoming\",\n",
    "        \"intent\": \"candidate_add\",\n",
    "        \"entities\": []\n",
    "      }, \n",
    "      {\n",
    "        \"text\": \"we have a new candidate for prescreening\",\n",
    "        \"intent\": \"candidate_add\",\n",
    "        \"entities\": []\n",
    "      },         \n",
    "      {\n",
    "        \"text\": \"correct\",\n",
    "        \"intent\": \"affirm\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"great choice\",\n",
    "        \"intent\": \"affirm\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"sounds really good\",\n",
    "        \"intent\": \"affirm\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"bye\", \n",
    "        \"intent\": \"goodbye\", \n",
    "        \"entities\": []\n",
    "      }, \n",
    "      {\n",
    "        \"text\": \"goodbye\", \n",
    "        \"intent\": \"goodbye\", \n",
    "        \"entities\": []\n",
    "      }, \n",
    "      {\n",
    "        \"text\": \"good bye\", \n",
    "        \"intent\": \"goodbye\", \n",
    "        \"entities\": []\n",
    "      }, \n",
    "      {\n",
    "        \"text\": \"stop\", \n",
    "        \"intent\": \"goodbye\", \n",
    "        \"entities\": []\n",
    "      }, \n",
    "      {\n",
    "        \"text\": \"end\", \n",
    "        \"intent\": \"goodbye\", \n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"farewell\",\n",
    "        \"intent\": \"goodbye\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"Bye bye\",\n",
    "        \"intent\": \"goodbye\",\n",
    "        \"entities\": []\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"have a good one\",\n",
    "        \"intent\": \"goodbye\",\n",
    "        \"entities\": []\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "training_data = open(\"anna.json\", \"w\")\n",
    "training_data.write(anna_common_examples)\n",
    "training_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install -U scikit-learn==0.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.model import Trainer, Interpreter\n",
    "from rasa_nlu.components import ComponentBuilder\n",
    "import rasa_nlu.config\n",
    "\n",
    "cfg = 'config.json'\n",
    "training_data = load_data('anna.json')\n",
    "trainer = Trainer(rasa_nlu.config.load(cfg))\n",
    "trainer.train(training_data)\n",
    "model_directory = trainer.persist('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the intent we use the parse method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': [],\n",
       " 'intent': {'confidence': 0.6837588947986979, 'name': 'affirm'},\n",
       " 'intent_ranking': [{'confidence': 0.6837588947986979, 'name': 'affirm'},\n",
       "  {'confidence': 0.2560145833911606, 'name': 'greet'},\n",
       "  {'confidence': 0.042431731595500566, 'name': 'goodbye'},\n",
       "  {'confidence': 0.017794790214640692, 'name': 'candidate_add'}],\n",
       " 'text': 'yes'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rasa_nlu.model import Metadata, Interpreter\n",
    "\n",
    "interpreter = Interpreter.load(model_directory)\n",
    "\n",
    "interpreter.parse(u\"yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it work?\n",
    "\n",
    "The training is divided into several parts as shown below.\n",
    "\n",
    "![](images/classifier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1. Train Rasa to discover new intent\n",
    "\n",
    "Extend the training examples and add an intent `change_status` with entities: `passed` and `failed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anna_common_examples = \n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\"\n",
    "training_data = open(\"anna_new.json\", \"w\")\n",
    "training_data.write(anna_common_examples)\n",
    "training_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.model import Trainer, Interpreter\n",
    "from rasa_nlu.components import ComponentBuilder\n",
    "import rasa_nlu.config\n",
    "\n",
    "cfg = 'config.json'\n",
    "training_data = load_data('anna_new.json')\n",
    "trainer = Trainer(rasa_nlu.config.load(cfg))\n",
    "trainer.train(training_data)\n",
    "model_directory = trainer.persist('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': [],\n",
       " 'intent': {'confidence': 0.6204533422709783, 'name': 'change_status'},\n",
       " 'intent_ranking': [{'confidence': 0.6204533422709783,\n",
       "   'name': 'change_status'},\n",
       "  {'confidence': 0.13981978300841671, 'name': 'affirm'},\n",
       "  {'confidence': 0.09130984094477532, 'name': 'candidate_add'},\n",
       "  {'confidence': 0.07576837710026818, 'name': 'goodbye'},\n",
       "  {'confidence': 0.07264865667556153, 'name': 'greet'}],\n",
       " 'text': \"the developer didn't passed\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rasa_nlu.model import Metadata, Interpreter\n",
    "\n",
    "interpreter = Interpreter.load(model_directory)\n",
    "\n",
    "interpreter.parse(u\"the developer didn't passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building stories with Rasa\n",
    "\n",
    "To build a chatbot with Rasa that has a focus on the context management, we need to build the dataset of intents as before, but also stories. \n",
    "\n",
    "\n",
    "![](images/intent_entities.png)\n",
    "\n",
    "Rasa core for building stories need a bit more configuration than in the previous example. We need to setup the following:\n",
    "- the configuration of language and machine learning backend,\n",
    "- setup the domain with sample chatbot responses,\n",
    "- define the stories.\n",
    "After this step we need to train Rasa, but we still need feed it with intents after it.\n",
    "\n",
    "A basic configuration for Rasa is needed like to language and pipeline. The pipeline defines the way how we want to train our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'rasa_config' (str) to file 'rasa_config.yml'.\n"
     ]
    }
   ],
   "source": [
    "rasa_config = \"\"\"\n",
    "policies:\n",
    "  - name: KerasPolicy\n",
    "    epochs: 100\n",
    "    max_history: 5\n",
    "  - name: FallbackPolicy\n",
    "    fallback_action_name: 'action_default_fallback'\n",
    "  - name: MemoizationPolicy\n",
    "    max_history: 5\n",
    "  - name: FormPolicy\n",
    "\"\"\"\n",
    "%store rasa_config > rasa_config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define a few stories for our chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'stories_md' (str) to file 'stories.md'.\n"
     ]
    }
   ],
   "source": [
    "stories_md = \"\"\"\n",
    "## happy path\n",
    "* greet\n",
    "  - utter_greet\n",
    "* mood_great\n",
    "  - utter_happy\n",
    "\n",
    "## sad path 1\n",
    "* greet\n",
    "  - utter_greet\n",
    "* mood_unhappy\n",
    "  - utter_cheer_up\n",
    "  - utter_did_that_help\n",
    "* mood_affirm\n",
    "  - utter_happy\n",
    "\n",
    "## sad path 2\n",
    "* greet\n",
    "  - utter_greet\n",
    "* mood_unhappy\n",
    "  - utter_cheer_up\n",
    "  - utter_did_that_help\n",
    "* mood_deny\n",
    "  - utter_goodbye\n",
    "\n",
    "## say goodbye\n",
    "* goodbye\n",
    "  - utter_goodbye\n",
    "\"\"\"\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set the domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'domain_yml' (str) to file 'domain.yml'.\n"
     ]
    }
   ],
   "source": [
    "domain_yml = \"\"\"\n",
    "intents:\n",
    "  - greet\n",
    "  - goodbye\n",
    "  - mood_affirm\n",
    "  - mood_deny\n",
    "  - mood_great\n",
    "  - mood_unhappy\n",
    "\n",
    "actions:\n",
    "- utter_greet\n",
    "- utter_cheer_up\n",
    "- utter_did_that_help\n",
    "- utter_happy\n",
    "- utter_goodbye\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "  - text: \"Hey! How are you?\"\n",
    "\n",
    "  utter_cheer_up:\n",
    "  - text: \"Here is something to cheer you up:\"\n",
    "    image: \"https://i.imgur.com/nGF1K8f.jpg\"\n",
    "\n",
    "  utter_did_that_help:\n",
    "  - text: \"Did that help you?\"\n",
    "\n",
    "  utter_happy:\n",
    "  - text: \"Great carry on!\"\n",
    "\n",
    "  utter_goodbye:\n",
    "  - text: \"Bye\"\n",
    "\"\"\"\n",
    "%store domain_yml > domain.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pykwalify/core.py:99: UnsafeLoaderWarning: \n",
      "The default 'Loader' for 'load(stream)' without further arguments can be unsafe.\n",
      "Use 'load(stream, Loader=ruamel.yaml.Loader)' explicitly if that is OK.\n",
      "Alternatively include the following in your code:\n",
      "\n",
      "  import warnings\n",
      "  warnings.simplefilter('ignore', ruamel.yaml.error.UnsafeLoaderWarning)\n",
      "\n",
      "In most other cases you should consider using 'safe_load(stream)'\n",
      "  data = yaml.load(stream)\n",
      "Processed Story Blocks: 100%|#####| 4/4 [00:00<00:00, 2202.02it/s, # trackers=1]\n",
      "Processed Story Blocks: 100%|######| 4/4 [00:00<00:00, 767.91it/s, # trackers=4]\n",
      "Processed Story Blocks: 100%|#####| 4/4 [00:00<00:00, 203.27it/s, # trackers=12]\n",
      "Processed Story Blocks: 100%|#####| 4/4 [00:00<00:00, 109.59it/s, # trackers=14]\n",
      "2018-11-22 11:38:44.655192: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking (Masking)            (None, 5, 15)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                6144      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 9)                 297       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 9)                 0         \n",
      "=================================================================\n",
      "Total params: 6,441\n",
      "Trainable params: 6,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "2018-11-22 11:38:45 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_core.policies.keras_policy\u001b[0m  - Fitting model with 62 total samples and a validation split of 0.1\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 1s 21ms/step - loss: 2.1607 - acc: 0.1774\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 103us/step - loss: 2.1088 - acc: 0.3226\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 161us/step - loss: 2.0970 - acc: 0.3226\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 188us/step - loss: 2.0965 - acc: 0.4194\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 149us/step - loss: 2.0673 - acc: 0.3548\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 113us/step - loss: 2.0644 - acc: 0.3710\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 122us/step - loss: 2.0352 - acc: 0.3871\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 161us/step - loss: 2.0449 - acc: 0.4194\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 97us/step - loss: 2.0194 - acc: 0.4355\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 212us/step - loss: 2.0160 - acc: 0.4032\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 120us/step - loss: 1.9956 - acc: 0.4516\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 103us/step - loss: 1.9743 - acc: 0.4355\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 112us/step - loss: 1.9963 - acc: 0.4677\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 228us/step - loss: 1.9495 - acc: 0.4194\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 109us/step - loss: 1.9442 - acc: 0.4355\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 186us/step - loss: 1.9232 - acc: 0.4194\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 126us/step - loss: 1.9186 - acc: 0.4355\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 115us/step - loss: 1.9051 - acc: 0.4355\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 110us/step - loss: 1.8802 - acc: 0.4355\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 133us/step - loss: 1.8716 - acc: 0.4355\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 237us/step - loss: 1.8670 - acc: 0.4355\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 292us/step - loss: 1.8502 - acc: 0.4355\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 137us/step - loss: 1.8250 - acc: 0.4516\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 111us/step - loss: 1.8193 - acc: 0.4355\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 112us/step - loss: 1.8177 - acc: 0.4355\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 84us/step - loss: 1.7770 - acc: 0.4355\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 130us/step - loss: 1.7622 - acc: 0.4516\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 286us/step - loss: 1.7500 - acc: 0.4355\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 102us/step - loss: 1.7814 - acc: 0.4355\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 138us/step - loss: 1.7601 - acc: 0.4355\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 104us/step - loss: 1.7027 - acc: 0.4355\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 116us/step - loss: 1.7016 - acc: 0.4355\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 113us/step - loss: 1.6983 - acc: 0.4355\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 109us/step - loss: 1.6899 - acc: 0.4355\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 233us/step - loss: 1.6894 - acc: 0.4516\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 162us/step - loss: 1.6562 - acc: 0.4355\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.6590 - acc: 0.4516\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 238us/step - loss: 1.6634 - acc: 0.4355\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 378us/step - loss: 1.6420 - acc: 0.4355\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 144us/step - loss: 1.6155 - acc: 0.4355\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 97us/step - loss: 1.6397 - acc: 0.4355\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 126us/step - loss: 1.6271 - acc: 0.4355\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 118us/step - loss: 1.6026 - acc: 0.4516\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 214us/step - loss: 1.6182 - acc: 0.4516\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 166us/step - loss: 1.5958 - acc: 0.4516\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 245us/step - loss: 1.6070 - acc: 0.4516\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 189us/step - loss: 1.5933 - acc: 0.4355\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 233us/step - loss: 1.5674 - acc: 0.4516\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 119us/step - loss: 1.5700 - acc: 0.4516\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 123us/step - loss: 1.5743 - acc: 0.4516\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 144us/step - loss: 1.5444 - acc: 0.4516\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 117us/step - loss: 1.5462 - acc: 0.4516\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 201us/step - loss: 1.5222 - acc: 0.4516\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 474us/step - loss: 1.5392 - acc: 0.4516\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 208us/step - loss: 1.5234 - acc: 0.4516\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 306us/step - loss: 1.5335 - acc: 0.4516\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 253us/step - loss: 1.5158 - acc: 0.4516\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 121us/step - loss: 1.5081 - acc: 0.4516\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 171us/step - loss: 1.5212 - acc: 0.4516\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 306us/step - loss: 1.5026 - acc: 0.4516\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 237us/step - loss: 1.4702 - acc: 0.4516\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 142us/step - loss: 1.4745 - acc: 0.4355\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 159us/step - loss: 1.4706 - acc: 0.4516\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 243us/step - loss: 1.4781 - acc: 0.4516\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 118us/step - loss: 1.4772 - acc: 0.4516\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 128us/step - loss: 1.4541 - acc: 0.4516\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 94us/step - loss: 1.4845 - acc: 0.4516\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 178us/step - loss: 1.4260 - acc: 0.4355\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 244us/step - loss: 1.4345 - acc: 0.4355\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 153us/step - loss: 1.4449 - acc: 0.4516\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 137us/step - loss: 1.4175 - acc: 0.4516\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 120us/step - loss: 1.3996 - acc: 0.4516\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 161us/step - loss: 1.4121 - acc: 0.4355\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 255us/step - loss: 1.4241 - acc: 0.4194\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 120us/step - loss: 1.4044 - acc: 0.4516\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 154us/step - loss: 1.3885 - acc: 0.4516\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 112us/step - loss: 1.3687 - acc: 0.4516\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 161us/step - loss: 1.4050 - acc: 0.4355\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 296us/step - loss: 1.3768 - acc: 0.4677\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 150us/step - loss: 1.3475 - acc: 0.4677\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 135us/step - loss: 1.3583 - acc: 0.4516\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 140us/step - loss: 1.3485 - acc: 0.4677\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 79us/step - loss: 1.3461 - acc: 0.4677\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 166us/step - loss: 1.3301 - acc: 0.4677\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 80us/step - loss: 1.3403 - acc: 0.4355\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 117us/step - loss: 1.3190 - acc: 0.4677\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 133us/step - loss: 1.3121 - acc: 0.4516\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 110us/step - loss: 1.3118 - acc: 0.4677\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 101us/step - loss: 1.3222 - acc: 0.4677\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 87us/step - loss: 1.3248 - acc: 0.4677\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 148us/step - loss: 1.2844 - acc: 0.4839\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 97us/step - loss: 1.2774 - acc: 0.4839\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 117us/step - loss: 1.2820 - acc: 0.4677\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 170us/step - loss: 1.2614 - acc: 0.4839\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 114us/step - loss: 1.2668 - acc: 0.4677\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 88us/step - loss: 1.2373 - acc: 0.5000\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 79us/step - loss: 1.2671 - acc: 0.4839\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 80us/step - loss: 1.2295 - acc: 0.5000\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 195us/step - loss: 1.2005 - acc: 0.5161\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 138us/step - loss: 1.2323 - acc: 0.5000\n",
      "2018-11-22 11:38:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_core.policies.keras_policy\u001b[0m  - Done fitting keras policy model\n",
      "Processed actions: 62it [00:00, 2108.00it/s, # examples=62]\n",
      "2018-11-22 11:38:49 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_core.agent\u001b[0m  - Model directory models/cisco exists and contains old model files. All files will be overwritten.\n",
      "2018-11-22 11:38:50 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_core.agent\u001b[0m  - Persisted model to '/home/codete/workshop/models/cisco'\n"
     ]
    }
   ],
   "source": [
    "!python3 -m rasa_core.train -c rasa_config.yml -d domain.yml -s stories.md -o models/krakow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'nlu.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "## intent:greet\n",
    "- hey\n",
    "- hello\n",
    "- hi\n",
    "- good morning\n",
    "- good evening\n",
    "- hey there\n",
    "\n",
    "## intent:goodbye\n",
    "- bye\n",
    "- goodbye\n",
    "- see you around\n",
    "- see you later\n",
    "\n",
    "## intent:mood_affirm\n",
    "- yes\n",
    "- indeed\n",
    "- of course\n",
    "- that sounds good\n",
    "- correct\n",
    "\n",
    "## intent:mood_deny\n",
    "- no\n",
    "- never\n",
    "- I don't think so\n",
    "- don't like that\n",
    "- no way\n",
    "- not really\n",
    "\n",
    "## intent:mood_great\n",
    "- perfect\n",
    "- very good\n",
    "- great\n",
    "- amazing\n",
    "- wonderful\n",
    "- I am feeling very good\n",
    "- I am great\n",
    "- I'm good\n",
    "\n",
    "## intent:mood_unhappy\n",
    "- sad\n",
    "- very sad\n",
    "- unhappy\n",
    "- bad\n",
    "- very bad\n",
    "- awful\n",
    "- terrible\n",
    "- not very good\n",
    "- extremely sad\n",
    "- so sad\n",
    "\"\"\"\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_config' (str) to file 'nlu_config.yml'.\n"
     ]
    }
   ],
   "source": [
    "nlu_config = \"\"\"\n",
    "language: en\n",
    "pipeline: tensorflow_embedding\n",
    "\"\"\"\n",
    "%store nlu_config > nlu_config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-22 11:40:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of nlu.md is md\n",
      "2018-11-22 11:40:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 39 (6 distinct intents)\n",
      "\t- Found intents: 'greet', 'mood_great', 'mood_deny', 'mood_affirm', 'mood_unhappy', 'goodbye'\n",
      "\t- entity examples: 0 (0 distinct entities)\n",
      "\t- found entities: \n",
      "\n",
      "2018-11-22 11:40:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component tokenizer_whitespace\n",
      "2018-11-22 11:40:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2018-11-22 11:40:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component ner_crf\n",
      "2018-11-22 11:40:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2018-11-22 11:40:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component ner_synonyms\n",
      "2018-11-22 11:40:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2018-11-22 11:40:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component intent_featurizer_count_vectors\n",
      "2018-11-22 11:40:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2018-11-22 11:40:46 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component intent_classifier_tensorflow_embedding\n",
      "2018-11-22 11:40:51.566607: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2018-11-22 11:40:51 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.classifiers.embedding_intent_classifier\u001b[0m  - Accuracy is updated every 10 epochs\n",
      "Epochs: 100%|#########| 300/300 [00:01<00:00, 159.79it/s, loss=0.096, acc=1.000]\n",
      "2018-11-22 11:40:53 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.classifiers.embedding_intent_classifier\u001b[0m  - Finished training embedding policy, loss=0.096, train accuracy=1.000\n",
      "2018-11-22 11:40:53 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2018-11-22 11:40:53 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Successfully saved model into '/home/codete/workshop/models/cisco/nlu'\n",
      "2018-11-22 11:40:53 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Finished training\n"
     ]
    }
   ],
   "source": [
    "!python3 -m rasa_nlu.train -c nlu_config.yml --data nlu.md -o models --fixed_model_name nlu --project lublin --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"chat-window\" <p>Hi! you can chat in this window. Type 'stop' to end the conversation.</p><p>Hi</p><p>Hey! How are you?</p><p>Great</p><p>Great carry on!</p></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n"
     ]
    }
   ],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output, HTML, display\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import RasaNLUInterpreter\n",
    "import time\n",
    "\n",
    "interpreter = RasaNLUInterpreter('models/lublin/nlu')\n",
    "messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "agent = Agent.load('models/lublin', interpreter=interpreter)\n",
    "\n",
    "def chatlogs_html(messages):\n",
    "    messages_html = \"\".join([\"<p>{}</p>\".format(m) for m in messages])\n",
    "    chatbot_html = \"\"\"<div class=\"chat-window\" {}</div>\"\"\".format(messages_html)\n",
    "    return chatbot_html\n",
    "\n",
    "\n",
    "while True:\n",
    "    clear_output()\n",
    "    display(HTML(chatlogs_html(messages)))\n",
    "    time.sleep(0.3)\n",
    "    a = input()\n",
    "    messages.append(a)\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    responses = agent.handle_message(a)\n",
    "    for r in responses:\n",
    "        messages.append(r.get(\"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Add a menu story for a restaurant\n",
    "\n",
    "You should be able to display the menu depending on the part of the menu like: starters, soups, main dishses, desserts and drinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your stories here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your domain here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rasa_core.train -d domain.yml -s stories.md -o models/restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put your intentes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m rasa_nlu.train -c nlu_config.yml --data nlu.md -o models --fixed_model_name nlu --project restaurant --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import clear_output, HTML, display\n",
    "from rasa_core.agent import Agent\n",
    "from rasa_core.interpreter import RasaNLUInterpreter\n",
    "import time\n",
    "\n",
    "interpreter = RasaNLUInterpreter('models/restaurant/nlu')\n",
    "messages = [\"Hi! you can chat in this window. Type 'stop' to end the conversation.\"]\n",
    "agent = Agent.load('models/restaurant', interpreter=interpreter)\n",
    "\n",
    "def chatlogs_html(messages):\n",
    "    messages_html = \"\".join([\"<p>{}</p>\".format(m) for m in messages])\n",
    "    chatbot_html = \"\"\"<div class=\"chat-window\" {}</div>\"\"\".format(messages_html)\n",
    "    return chatbot_html\n",
    "\n",
    "\n",
    "while True:\n",
    "    clear_output()\n",
    "    display(HTML(chatlogs_html(messages)))\n",
    "    time.sleep(0.3)\n",
    "    a = input()\n",
    "    messages.append(a)\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    responses = agent.handle_message(a)\n",
    "    for r in responses:\n",
    "        messages.append(r.get(\"text\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
